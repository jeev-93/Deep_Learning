{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8SC3p-UCusw"
   },
   "source": [
    "# RNN Machine Translation Laboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvKNkEYrCusy"
   },
   "source": [
    "In this lab, your task is to build a sequence-to-sequence model, using recurrent neural networks, that translates short sentences from Swedish into English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Tensorflow is quite chatty; filter out warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IDNS-GhLCusz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that Tensorflow uses a GPU _(optional)_\n",
    "\n",
    "Training the models in this notebook can be sped up significantly with a GPU.  The following cell can be used to check if the GPU is set up correctly.  If you run on CPU, you can either run or just ignore this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Tensorflow has NOT detected a GPU.\n",
      "\n",
      "For GPU support, visit: <https://www.tensorflow.org/install/pip>\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "if tf.config.list_physical_devices(\"GPU\"):\n",
    "    print(\"✓ Tensorflow has detected a GPU.\")\n",
    "    import shutil\n",
    "    if not shutil.which(\"ptxas\"):\n",
    "        print(\"\\n✗ Command 'ptxas' not found in path -- you might have to install `cudatoolkit-dev`\")\n",
    "    if not \"XLA_FLAGS\" in os.environ:\n",
    "        print(\"\\n✗ XLA_FLAGS not set. If you encounter errors during training, you might have to set\")\n",
    "        print(\"        XLA_FLAGS=\\\"--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib/\\\"\")\n",
    "    \n",
    "    # Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "else:\n",
    "    print(\"✗ Tensorflow has NOT detected a GPU.\")\n",
    "    print()\n",
    "    print(\"For GPU support, visit: <https://www.tensorflow.org/install/pip>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Specification\n",
    "\n",
    "Your task in this assignment is to:\n",
    "\n",
    "1. Build an encoder—decoder model based on recurrent neural networks.\n",
    "2. Train this model on the provided training data, a collection of parallel Swedish–English sentences.\n",
    "3. Evaluate the performance of this model on the provided test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX-5kU7mCus1"
   },
   "source": [
    "### The data: Swedish–English Anki corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luSjyoOqCus2"
   },
   "source": [
    "The data in this lab consists of bilingual Swedish–English sentence pairs from the [Tatoeba Project](https://tatoeba.org/en) as collected by [Anki](http://www.manythings.org/anki/).  These are comparatively short sentences, suitable for language learners, and therefore also well-suited for building a small machine translation model. Here are some example sentences from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EaFUyzF-Cus2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i returned to japan .', 'jag Ã¥tervÃ¤nde till japan .']\n",
      "['i love her .', 'jag Ã¤lskar henne .']\n",
      "[\"this is tom ' s school .\", 'detta Ã¤r toms skola .']\n",
      "['i can hardly stand .', 'jag kan knappt stÃ¥ .']\n"
     ]
    }
   ],
   "source": [
    "with open(\"en-sv-train.txt\", \"rt\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        pair = [sent for sent in line.rstrip().split(\"\\t\")]\n",
    "        print(pair)\n",
    "        if i > 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVYZFLVyCus3"
   },
   "source": [
    "Each line in the data files consists of an English–Swedish sentence pair. The sentences are already lower-cased and pre-tokenized (using the [toktok tokenizer from NLTK](https://www.nltk.org/howto/tokenize.html)), so we can simply split them up by whitespace to get sequences of tokens.  To make your life a bit easier, we have removed sentences longer than 15 words. \n",
    "\n",
    "The next cell contains code that yields the sentences contained in a file as lists of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Eay_PCwACus4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'returned', 'to', 'japan', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH = 0\n",
    "SWEDISH = 1\n",
    "\n",
    "def sentences(filename, idx):\n",
    "    # Use idx=0 for English, idx=1 for Swedish\n",
    "    with open(filename, \"rt\", encoding=\"utf-8\") as source:\n",
    "        for line in source:\n",
    "            yield line.rstrip().split(\"\\t\")[idx].split()\n",
    "\n",
    "# Example usage\n",
    "next(sentences(\"en-sv-train.txt\", ENGLISH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ypi63gGlCus5"
   },
   "source": [
    "## Part 1: Build the vocabularies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REbT89KqCus5"
   },
   "source": [
    "Before we can feed them into any model, we first need to convert the text strings to integers. For this purpose, we'll create a **vocabulary** of tokens that are known to the model, one vocabulary for each language. We need four **special tokens (or \"pseudowords\")**:\n",
    "\n",
    "1. `<pad>` at index 0 for padding purposes\n",
    "2. `<unk>` at index 1 to represent unknown words\n",
    "3. `<bos>` at index 2 to mark the \"beginning of sequence\" in the decoder\n",
    "4. `<eos>` at index 3 to mark the \"end of sequence\" in the decoder\n",
    "\n",
    "The remaining items in the vocabulary should be made up of the **most frequent words** in the training data for the respective language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 🤔 Task 1: Write the function to build the vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R29hmyaRCus5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_vocab(sentences, max_size):\n",
    "    \"\"\"Return a list of the `max_size` most frequent tokens in `sentences`.\"\"\"\n",
    "\n",
    "    vocabulary = ['<pad>', '<unk>', '<bos>', '<eos>']\n",
    "               \n",
    "    frequentWords = {}\n",
    "    #{wordA:count}\n",
    "    try:\n",
    "            \n",
    "        # TODO\n",
    "        # 1. Count of how often each word occurs in the data\n",
    "        for line in sentences:\n",
    "            for word in line:\n",
    "                if word in frequentWords:\n",
    "                    frequentWords[word] += 1\n",
    "                else:\n",
    "                    frequentWords[word] = 1\n",
    "        # 2. Sort the words by their frequency, in descending order\n",
    "        frequentOrderedList = sorted(frequentWords,key=lambda key: frequentWords[key], reverse=True)\n",
    "        # 3. Make a list of the special tokens plus the most frequent words, up to a length of `max_size`.\n",
    "        vocabulary.extend(frequentOrderedList)\n",
    "        vocabularyInitials = vocabulary[:max_size]\n",
    "        # 4. Return the list\n",
    "        return vocabularyInitials\n",
    "    except:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zmr7Oe9cCus7"
   },
   "source": [
    "With this function, we can construct vocabularies containing the 5,000 most frequent words as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "onyml-oDCus7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_vocab = make_vocab(sentences('en-sv-train.txt', SWEDISH), 5000)\n",
    "tgt_vocab = make_vocab(sentences('en-sv-train.txt', ENGLISH), 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX9T47dnCus8"
   },
   "source": [
    "#### 🤞 Test your code\n",
    "\n",
    "To test your code, check that each vocabulary contains 5,000 words, and includes the pseudowords at the right positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tZBil9ezCus8",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good!\n"
     ]
    }
   ],
   "source": [
    "def test1():\n",
    "    assert len(src_vocab) == 5000\n",
    "    assert len(tgt_vocab) == 5000\n",
    "    assert src_vocab[:4] == ['<pad>', '<unk>', '<bos>', '<eos>']\n",
    "    assert tgt_vocab[:4] == ['<pad>', '<unk>', '<bos>', '<eos>']\n",
    "    print(\"All good!\")\n",
    "\n",
    "test1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap the vocabularies in StringLookup layers\n",
    "\n",
    "For mapping tokens to their vocabulary IDs, we can use Keras' `StringLookup` layer. The next cell constructs layers for both the source and target vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "string_lookup_args = dict(output_mode=\"int\", mask_token=\"<pad>\", oov_token=\"<unk>\")\n",
    "src_lookup = layers.StringLookup(vocabulary=src_vocab, **string_lookup_args)\n",
    "tgt_lookup = layers.StringLookup(vocabulary=tgt_vocab, **string_lookup_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell gives an example how these `StringLookup` layers can be used. Note that the layers already return *tensors*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([   5 1005   11  530  188    4], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "example = \"i returned to japan yesterday .\".split()\n",
    "print(tgt_lookup(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤔 Task 2: Sanity-check that these numbers are correct\n",
    "\n",
    "Check your understanding of what's happening in the `StringLookup` layer by writing two lines of code:\n",
    "1. One that prints the token corresponding to the _second integer_ in the tensor above.\n",
    "2. One that prints the integer corresponding to the _second word_ (\"returned\") in the example above.\n",
    "\n",
    "Use `tgt_vocab` directly for that, not the lookup layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jungle\n",
      "1005\n"
     ]
    }
   ],
   "source": [
    "## TODO: Your code here\n",
    "print(tgt_vocab[1234])\n",
    "print(tgt_vocab.index('returned'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2fQzgkPCus9"
   },
   "source": [
    "### Wrapping everything in data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MF4JRJVCus9"
   },
   "source": [
    "The next cell defines a function that wraps our dataset in TensorFlow's [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) API, which represents map-style datasets. The advantage of this is that it lets us use standard infrastructure related to the loading and automatic batching of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TkFTb0LkCus9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def append_eos(tensor):\n",
    "    \"Helper function that appends '<eos>' to a sequence.\"\n",
    "    return tf.concat([tensor, tf.constant([\"<eos>\"], dtype=tf.string)], axis=0)\n",
    "\n",
    "def load_translation_dataset(src_lookup, tgt_lookup, filename):\n",
    "    # Build source dataset and convert with src_lookup\n",
    "    src_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        tf.ragged.constant(list(sentences(filename, SWEDISH)))\n",
    "    )\n",
    "    src_dataset = src_dataset.map(src_lookup)\n",
    "\n",
    "    # Build target dataset, append <eos> and convert with tgt_lookup\n",
    "    tgt_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        tf.ragged.constant(list(sentences(filename, ENGLISH)))\n",
    "    )\n",
    "    tgt_dataset = tgt_dataset.map(append_eos).map(tgt_lookup)\n",
    "    \n",
    "    # Zip them together\n",
    "    return tf.data.Dataset.zip((src_dataset, tgt_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnPlzxWrCus-"
   },
   "source": [
    "We load the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t1tyWbfbCus-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = load_translation_dataset(src_lookup, tgt_lookup, \"en-sv-train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoUAW-GcCus_"
   },
   "source": [
    "The following function can be helpful for debugging. It extracts a single source–target pair of sentences from the specified *dataset* and converts it into batches of size&nbsp;1, which can be fed into the encoder–decoder model. This also illustrates how the `Dataset` API works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DC2j_oZyCus_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def example(dataset, i):\n",
    "    if i > 0:\n",
    "        dataset = dataset.skip(i-1)\n",
    "    return list(dataset.take(1).batch(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dYhTBym7Cus_",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[  6  10 245  15  20   7]], shape=(1, 6), dtype=int64)\n",
      "tf.Tensor([[ 29   9 477  55  28   8   3]], shape=(1, 7), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x, y = example(train_dataset, 42)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw62gfhdCutA"
   },
   "source": [
    "## Part 2: The encoder–decoder architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB280fFjCutA"
   },
   "source": [
    "In this section, you will implement the encoder–decoder architecture, including the extension of that architecture by an attention mechanism. The implementation consists of four parts: the encoder, the attention mechanism, the decoder, and a class that wraps the complete architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUFFRKwGCutA"
   },
   "source": [
    "### Part 2.1: Implement the encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKeHOZyxCutA"
   },
   "source": [
    "The encoder is a component that takes an input tensor of vocabulary IDs, like the `x` tensor from the example above, and performs the following steps:\n",
    "\n",
    "1. Look up **word embeddings** for each token in the sequence.\n",
    "2. Process them with a **bi-directional recurrent neural network**. This works with any type of RNN, but we will use **GRU (gated recurrent unit) layers** throughout this laboration.\n",
    "3. Feed the output through a linear layer. We also take the last hidden state of the forward GRU and the last hidden state of the backward GRU, concatenate them, and pass them through a linear layer. This produces a \"summary\" of the source sentence, which we will later feed into the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the encoder by defining it as a **custom Keras layer.** For this, we have to define a class that subclasses from `keras.layers.Layer`, instantiate all required model weights and/or (sub)layers in the `__init__()` function, and uses them to perform the layer's computation in the `call()` function. Below is some skeleton code to get you started; you can also [read more about making custom layers in the Keras Docs](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤔 Task 3: Implement the encoder by completing the skeleton code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "klNT7vTPCutB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, num_words, embedding_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        # TODO: Add your code here that defines the required layers/weights\n",
    "        self.embedding = layers.Embedding(input_dim = num_words, output_dim = embedding_dim, mask_zero = True)\n",
    "        self.rnn = layers.Bidirectional(layers.GRU(hidden_dim, return_sequences = True, return_state = True))\n",
    "        self.linear = layers.Dense(hidden_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # TODO\n",
    "        # 1. Look up the embeddings for the source words\n",
    "        inputVals = self.embedding(inputs)\n",
    "        # 2. Apply a bi-directional GRU over the source sequences\n",
    "        rnnOutput, forward, backward  = self.rnn(inputVals)\n",
    "        # 3. Apply a linear transformation to the GRU's output\n",
    "        FinalOutput = self.linear(rnnOutput)\n",
    "        # 4. Concatenate forward + backward hidden states and apply a linear transformation on them too\n",
    "        state = layers.concatenate([forward, backward],axis=1)\n",
    "        hidden = self.linear(state)\n",
    "        return (FinalOutput, hidden)\n",
    "\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut1QP_1hCutB"
   },
   "source": [
    "Your code must comply with the following specification:\n",
    "\n",
    "**__init__** (*num_words*, *embedding_dim* = 128, *hidden_dim* = 256)\n",
    "\n",
    "> Initialises the encoder. The encoder consists of an embedding layer that maps each of *num_words* words to an embedding vector of size *embedding_dim*, a bidirectional GRU that maps each embedding vector to a position-specific representation of size 2 × *hidden_dim*, and a final linear layer that projects these representations to new representations of size *hidden_dim*.\n",
    "\n",
    "**call** (*self*, *inputs*)\n",
    "\n",
    "> Takes a tensor *inputs* with source-language word ids and sends it through the encoder. The input tensor has shape (*batch_size*, *src_len*), where *src_len* is the length of the sentences in the batch. (We will make sure that all sentences in the same batch have the same length.) The method returns a pair of tensors (*output*, *hidden*), where *output* has shape (*batch_size*, *src_len*, *hidden_dim*), and *hidden* has shape (*batch_size*, *hidden_dim*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xybpq39KCutC"
   },
   "source": [
    "#### 🤞 Test your code\n",
    "\n",
    "To test your code, instantiate an encoder, feed it the first source sentence in the training data, and check that the tensors returned by the encoder have the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LU4SIh0NCutC",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 256)\n",
      "(1, 256)\n"
     ]
    }
   ],
   "source": [
    "def test21():\n",
    "    src, tgt = example(train_dataset, 42)\n",
    "    encoder = Encoder(src_lookup.vocabulary_size())\n",
    "    output, hidden = encoder(src)\n",
    "    print(output.shape)  # should be (batch_size, src_len, hidden_dim)\n",
    "    print(hidden.shape)  # should be (batch_size, hidden_dim)\n",
    "\n",
    "test21()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnD4At5uCutD"
   },
   "source": [
    "### Part 2.2: Implement the attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twmxl69tCutD"
   },
   "source": [
    "Your next task is to implement the attention mechanism. Recall that the purpose of this mechanism is to inform the decoder when generating the translation of the next word. For this, attention has access to the previous hidden state of the decoder, as well as the complete output of the encoder. It returns the attention-weighted sum of the encoder output, the so-called *context* vector. For later usage, we also return the attention weights.\n",
    "\n",
    "As mentioned in the lecture, attention can be implemented in various ways. One very simple implementation is *uniform attention*, which assigns equal weight to each position-specific representation in the output of the encoder, and completely ignores the hidden state of the decoder. This mechanism is implemented in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VK4LsCUfCutD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UniformAttention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, decoder_hidden, encoder_output, mask=None):\n",
    "        # Set all attention scores to the same constant value (0). After\n",
    "        # the softmax, we will have uniform weights.\n",
    "        scores = tf.zeros_like(encoder_output[:, :, -1])\n",
    "        \n",
    "        # Mask out the attention scores for the padding tokens. We set\n",
    "        # them to -inf. After the softmax, we will have 0.\n",
    "        if mask is not None:\n",
    "            masked_value = -float('inf') * tf.ones_like(scores)\n",
    "            scores = tf.where(mask, scores, masked_value)\n",
    "        \n",
    "        # Convert scores into weights\n",
    "        alpha = tf.nn.softmax(scores, axis=1)\n",
    "        \n",
    "        # The context is the alpha-weighted sum of the encoder outputs.\n",
    "        context = tf.linalg.matmul(tf.expand_dims(alpha, axis=1), encoder_output)\n",
    "        context = tf.squeeze(context, axis=1)\n",
    "        \n",
    "        return alpha, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYs0hSHCutE"
   },
   "source": [
    "One technical detail in this code is our use of *mask* to compute attention weights only for the ‘real’ tokens in the source sentences, but not for the padding tokens that we introduce to bring all sentences in a batch to the same length.\n",
    "\n",
    "Your task now is to implement the attention mechanism from the paper by [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473). The relevant equation is in Section&nbsp;A.1.2:\n",
    "\n",
    "$$\n",
    "a(s_{i-1}, h_j) = v^{\\top} \\tanh(W s_{i-1} + U h_j)\n",
    "$$\n",
    "\n",
    "This equation specifies how to compute the attention score (a scalar) for the previous hidden state of the decoder, denoted by $s_{i-1}$, and the $j$-th position-specific representation in the output of the encoder, denoted by $h_j$. The equation refers to three parameters: a vector $v$ and $W$ and $U$. In PyTorch, these parameters can be represented in terms of (bias-free) linear layers that are trained along with the other parameters of the model.\n",
    "\n",
    "Here is the skeleton code for this problem. As you can see, your specific task is to initialise the required parameters and to compute the attention scores (*scores*); the rest of the code is the same as for the uniform attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤔 Task 4: Implement Bahdanau attention by completing the skeleton code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RyclW2osCutE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(layers.Layer):\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.supports_masking = True\n",
    "        # TODO: Add your code here that defines the required layers/weights\n",
    "        self.w = layers.Dense(hidden_dim)\n",
    "        self.u = layers.Dense(hidden_dim)\n",
    "        self.v = layers.Dense(1)\n",
    "\n",
    "    def call(self, decoder_hidden, encoder_output, mask=None):\n",
    "        # TODO: Replace the next line with your own code that computes the attention scores\n",
    "        uEncoder = self.u(encoder_output) \n",
    "        wDecoder = self.w(tf.expand_dims(decoder_hidden, 1)) \n",
    "        scores = self.v(tf.nn.tanh(uEncoder+wDecoder)) \n",
    "        scores = tf.squeeze(scores, axis=2) \n",
    "\n",
    "        # ... The rest of the code is as in UniformAttention — NO NEED TO MODIFY BELOW THIS LINE!\n",
    "\n",
    "        # Mask out the attention scores for the padding tokens. We set\n",
    "        # them to -inf. After the softmax, we will have 0.\n",
    "        if mask is not None:\n",
    "            masked_value = -float('inf') * tf.ones_like(scores)\n",
    "            scores = tf.where(mask, scores, masked_value)\n",
    "        \n",
    "        # Convert scores into weights\n",
    "        alpha = tf.nn.softmax(scores, axis=1)\n",
    "        \n",
    "        # The context is the alpha-weighted sum of the encoder outputs.\n",
    "        context = tf.linalg.matmul(tf.expand_dims(alpha, axis=1), encoder_output)\n",
    "        context = tf.squeeze(context, axis=1)\n",
    "        \n",
    "        return alpha, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTB0RPfDCutF"
   },
   "source": [
    "Your code must comply with the following specification:\n",
    "\n",
    "**call** (*decoder_hidden*, *encoder_output*, *mask*)\n",
    "\n",
    "> Takes the previous hidden state of the decoder (*decoder_hidden*) and the encoder output (*encoder_output*) and returns a pair (*alpha*, *context*) where *context* is the context as computed as in [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473), and *alpha* are the corresponding attention weights. The hidden state has shape (*batch_size*, *hidden_dim*), the encoder output has shape (*batch_size*, *src_len*, *hidden_dim*), the context has shape (*batch_size*, *hidden_dim*), and the attention weights have shape (*batch_size*, *src_len*).\n",
    "\n",
    "#### 💡 Hints on the implementation\n",
    "\n",
    "You may need a few more \"low-level\" TensorFlow functions to implement this part, concretely:\n",
    "    \n",
    "- `tf.expand_dims()` and `tf.squeeze()` to add/remove a dimension from a tensor. This is because some tensors have a \"timestep\" dimension while others (e.g. the hidden state of the decoder) don't.\n",
    "- `tf.nn.tanh()` to compute the $\\tanh$ function on a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxNwwlmuCutF"
   },
   "source": [
    "#### 🤞 Test your code\n",
    "\n",
    "To test your code, extend your test from Task 3: Feed the output of your encoder into your attention class. As the previous hidden state of the decoder, you can use the hidden state returned by the encoder. Later, you don't need to pass the mask explicitly (Keras will do this automatically), but for testing purposes, you can obtain the mask from a layer's output via `output._keras_mask`.\n",
    "\n",
    "Check that the context tensor and the attention weights returned by the attention class have the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZUqLpHXiCutG",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n",
      "(1, 256)\n"
     ]
    }
   ],
   "source": [
    "def test22():\n",
    "    src, tgt = example(train_dataset, 42)\n",
    "    encoder = Encoder(src_lookup.vocabulary_size())\n",
    "    output, hidden = encoder(src)\n",
    "    attention = BahdanauAttention()\n",
    "    alpha, context = attention(hidden, output, mask=output._keras_mask)\n",
    "    print(alpha.shape)    # should be (batch_size, src_len)\n",
    "    print(context.shape)  # should be (batch_size, hidden_dim)\n",
    "\n",
    "test22()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fB2A4Qa1CutG"
   },
   "source": [
    "### Part 2.3: Implement the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AO_4A4XXCutH"
   },
   "source": [
    "Now you are ready to implement the decoder. Like the encoder, the decoder is based on a GRU; but this time we use a unidirectional network, as we generate the target sentences left-to-right.\n",
    "\n",
    "**⚠️ We expect that solving this problem will take you the longest time in this lab.**\n",
    "\n",
    "Because the decoder is an autoregressive model, we need to unroll the GRU \"manually\": At each position, we take the previous hidden state as well as the new input, and apply the GRU for one step. The initial hidden state comes from the encoder. The new input is the embedding of the previous word, concatenated with the context vector from the attention model. To produce the final output, we take the output of the GRU, concatenate the embedding vector and the context vector (residual connection), and feed the result into a linear layer. Here is a graphical representation:\n",
    "\n",
    "<img src=\"https://gitlab.liu.se/nlp/nlp-course/-/raw/master/labs/l3/decoder.svg\" width=\"50%\" alt=\"Decoder architecture\"/>\n",
    "\n",
    "We need to implement this manual unrolling for two very similar tasks: When *training*, both the inputs to and the target outputs of the GRU come from the training data. When *decoding*, the outputs of the GRU are used to generate new target-side words, and these words become the inputs to the next step of the unrolling. **We have already implemented the `call` method that handles both these two different modes of usage — you don't need to modify this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤔 Task 5: Implement the `step` method that takes a single step with the GRU\n",
    "\n",
    "You will also need to add any necessary layers/weights that you use in the `__init__` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xBDjsJ-1CutH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, trg_lookup, attention, embedding_dim=128, hidden_dim=256, max_len=16):\n",
    "        super().__init__()\n",
    "        num_words = trg_lookup.vocabulary_size()\n",
    "        self.embedding = layers.Embedding(num_words, embedding_dim, mask_zero=True)\n",
    "        self.bos_index = trg_lookup([\"<bos>\"]).numpy()\n",
    "        self.max_len = max_len\n",
    "        # TODO: Add your code here that defines the required layers/weights\n",
    "        self.attention = BahdanauAttention()\n",
    "        self.rnn_cell = layers.GRUCell(hidden_dim)\n",
    "        self.linear = layers.Dense(num_words)\n",
    "\n",
    "    def call(self, encoder_output, initial_state, targets=None, training=False, mask=None):\n",
    "        # YOU WON'T NEED TO MODIFY ANYTHING IN THIS FUNCTION.\n",
    "\n",
    "        if training:\n",
    "            assert targets is not None\n",
    "\n",
    "        # Initialise the hidden state from `initial_state`\n",
    "        state = initial_state\n",
    "        \n",
    "        # Initialise the decoder input with the `<bos>` symbol\n",
    "        next_input = self.bos_index * tf.ones_like(initial_state, dtype=tf.int64)\n",
    "        next_input = next_input[:, 0]\n",
    "        \n",
    "        # Initialise the list of outputs and attention weights\n",
    "        outputs = tf.TensorArray(\n",
    "            tf.float32,\n",
    "            size=0 if training else self.max_len,\n",
    "            dynamic_size=training,\n",
    "        )\n",
    "        alphas = tf.TensorArray(\n",
    "            tf.float32,\n",
    "            size=0 if training else self.max_len,\n",
    "            dynamic_size=training,\n",
    "        )\n",
    "        inputs = tf.TensorArray(\n",
    "            tf.int64,\n",
    "            size=0 if training else self.max_len,\n",
    "            dynamic_size=training,\n",
    "        )\n",
    "\n",
    "        # In training mode, we iterate over the length of the target sentences,\n",
    "        # otherwise we iterate until `self.max_len` is reached\n",
    "        max_len = tf.shape(targets)[1] if training else self.max_len\n",
    "        \n",
    "        for i in range(max_len):\n",
    "            # In training mode, we feed the correct (gold) predictions as the next input\n",
    "            if training and i > 0:\n",
    "                next_input = targets[:, i-1]\n",
    "            \n",
    "            # Get the embedding for the previous word\n",
    "            prev_embed = self.embedding(next_input)\n",
    "            \n",
    "            # Take one step with the RNN\n",
    "            step_output, state, alpha = self.step(encoder_output, state, prev_embed, mask=mask)\n",
    "            \n",
    "            # Update the list of generated words and attention weights\n",
    "            outputs = outputs.write(i, step_output)\n",
    "            alphas = alphas.write(i, alpha)\n",
    "            inputs = inputs.write(i, next_input)\n",
    "\n",
    "            # Set the prediction with highest probability as the input for the next timestep\n",
    "            if not training:\n",
    "                next_input = tf.math.argmax(step_output, axis=-1)\n",
    "\n",
    "        # Lists of outputs and attention weights are [tgt_len, batch_size, *],\n",
    "        # so we transpose them to have the batch dimension in first place again.\n",
    "        outputs = tf.transpose(outputs.stack(), perm=[1,0,2])\n",
    "        alphas = tf.transpose(alphas.stack(), perm=[1,0,2])\n",
    "        inputs = tf.transpose(inputs.stack(), perm=[1,0])\n",
    "        outputs._keras_mask = (inputs != 0)\n",
    "        \n",
    "        return outputs, alphas\n",
    "    \n",
    "    def step(self, encoder_output, hidden_state, prev_embed, mask=None):\n",
    "        # TODO: Replace the next line with your own code; this should follow the illustration above.\n",
    "        # 1. Get the attention weights and context vector\n",
    "        alpha, context = self.attention(hidden_state, encoder_output, mask=mask)\n",
    "        # 2. Concatenate the inputs for the GRU\n",
    "        rnn_input = layers.concatenate([context, prev_embed],axis=1)\n",
    "        # 3. Take one step with the GRU cell\n",
    "        rnn_output, hidden_state = self.rnn_cell(rnn_input, hidden_state)\n",
    "        # 4. Concatenate the respective tensors to produce the final output\n",
    "        output = layers.concatenate([rnn_input, rnn_output],axis=1)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        \n",
    "        return output, hidden_state, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ej2-lzyVCutH"
   },
   "source": [
    "Your implementation should comply with the following specification:\n",
    "\n",
    "**step** (*self*, *encoder_output*, *hidden*, *prev_embed*, *mask*)\n",
    "\n",
    "> Performs a single step in the manual unrolling of the decoder GRU. This takes the output of the encoder (*encoder_output*), the previous hidden state of the decoder (*hidden*), the embedding vector of the previous word (*prev_embed*), and the source mask as described in Problem&nbsp;2.2 (*mask*), and computes the output as described above.\n",
    ">\n",
    "> The shape of *encoder_output* is (*batch_size*, *src_len*, *hidden_dim*); the shape of *hidden* is (*batch_size*, *hidden_dim*); the shape of *src_mask* is (*batch_size*, *src_len*); and the shape of *prev_embed* is (*batch_size*, *embedding_dim*).\n",
    ">\n",
    "> The method returns a triple of tensors (*output*, *hidden*, *alpha*) where *output* is the position-specific output of the GRU, of shape (*batch_size*, *num_words*); *hidden* is the new hidden state, of shape (*batch_size*, *hidden_dim*); and *alpha* are the attention weights that were used to compute the *output*, of shape (*batch_size*, *src_len*).\n",
    "\n",
    "#### 💡 Hints on the implementation\n",
    "\n",
    "**GRU vs. GRUCell.** In Keras, an RNN layer like `GRU` is used to process an entire sequence. A single *time-step* of a sequence is handled by a [`GRUCell`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell) instead. You can think of a `GRU` layer as functionally equivalent to a for-loop around a `GRUCell`. Since we want to perform the RNN steps individually for this model, you should use a [`GRUCell`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell) instead of a `GRU` layer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFvNiX-YCutI"
   },
   "source": [
    "#### 🤞 Test your code\n",
    "\n",
    "To test your code, extend your test from the previous problems, and simulate a complete forward pass of the encoder–decoder architecture on the example sentence. Check the shapes of the resulting tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "65lLG-bBCutI",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 16, 5000)\n",
      "(4, 16, 5)\n",
      "(4, 8, 5000)\n"
     ]
    }
   ],
   "source": [
    "def test23():\n",
    "    src, tgt = list(train_dataset.take(4).padded_batch(4))[0]\n",
    "    encoder = Encoder(src_lookup.vocabulary_size())\n",
    "    encoder_output, hidden = encoder(src)\n",
    "    attention = BahdanauAttention()\n",
    "    decoder = Decoder(tgt_lookup, attention)\n",
    "    decoded, alphas = decoder(encoder_output, hidden)\n",
    "    print(decoded.shape)  # should be (batch_size, max_len, vocabulary_size)\n",
    "    print(alphas.shape)   # should be (batch_size, max_len, src_len)\n",
    "    decoded, _ = decoder(encoder_output, hidden, targets=tgt, training=True)\n",
    "    print(decoded.shape)  # should be (batch_size, tgt_len, vocabulary_size)\n",
    "\n",
    "test23()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70yHTFS9CutJ"
   },
   "source": [
    "### Encoder–Decoder wrapper class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeKfvES5CutJ"
   },
   "source": [
    "The last part of the implementation is a class that wraps the encoder and the decoder as a single model.  We also implement a custom `train_step` function so that the gold targets will get passed to the decoder during training, and a custom `test_step` function to make sure the decoded sequences and the gold sequences are padded to the same length before computing losses and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lUjIGniZCutJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(keras.Model):\n",
    "    def __init__(self, src_lookup, tgt_lookup, embedding_dim=128, hidden_dim=256, max_len=16, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = Encoder(\n",
    "            src_lookup.vocabulary_size(),\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            tgt_lookup,\n",
    "            BahdanauAttention(hidden_dim=hidden_dim),\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            max_len=max_len,\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs, training=False, targets=None):\n",
    "        x_out, x_hidden = self.encoder(inputs, training=training)\n",
    "        outputs, alphas = self.decoder(x_out, x_hidden, training=training, targets=targets)\n",
    "        if training:\n",
    "            return outputs\n",
    "        else:\n",
    "            return outputs, alphas\n",
    "    \n",
    "    # Following <https://keras.io/guides/customizing_what_happens_in_fit/>\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Here we supply \"targets\" so that the decoder has access to it\n",
    "            y_pred = self(x, training=True, targets=y)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred, _alphas = self(x, training=False)\n",
    "\n",
    "        # Pad sequences to the same number of time-steps\n",
    "        max_len = tf.math.maximum(tf.shape(y)[1], tf.shape(y_pred)[1])\n",
    "        y_pad = [[0, 0], [0, max_len - tf.shape(y)[1]]]\n",
    "        y = tf.pad(y, y_pad)\n",
    "        y_pred_pad = [[0, 0], [0, max_len - tf.shape(y_pred)[1]], [0, 0]]\n",
    "        y_pred = tf.pad(y_pred, y_pred_pad)\n",
    "            \n",
    "        self.compute_loss(x, y, y_pred, None)\n",
    "        return self.compute_metrics(x, y, y_pred, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3uW3TKACutK"
   },
   "source": [
    "#### 🤞 Test your code\n",
    "\n",
    "As a final test, instantiate an encoder–decoder model and use it to decode the example sentence. Check the shapes of the resulting tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oO6zONDwCutK",
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 5000)\n",
      "(1, 16, 6)\n"
     ]
    }
   ],
   "source": [
    "def test24():\n",
    "    src, tgt = example(train_dataset, 42)\n",
    "    encoder_decoder = EncoderDecoder(src_lookup, tgt_lookup)\n",
    "    outputs, alphas = encoder_decoder(src)\n",
    "    print(outputs.shape)  # should be (batch_size, max_len, vocabulary_size)\n",
    "    print(alphas.shape)   # should be (batch_size, max_len, src_len)\n",
    "\n",
    "test24()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laK9bbq8CutL"
   },
   "source": [
    "## Part 3: Train a translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q68aWc_2CutL"
   },
   "source": [
    "We now have all the pieces to build and train a complete translation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5MYw2PJCutL"
   },
   "source": [
    "### Translator class\n",
    "\n",
    "We first define a class `Translator` that initialises an encoder–decoder model and uses it to translate sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Evi-J7BfCutM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self, src_lookup, tgt_lookup, batch_size=32, **kwargs):\n",
    "        self.src_lookup = src_lookup\n",
    "        self.tgt_lookup = tgt_lookup\n",
    "        self.model = EncoderDecoder(src_lookup, tgt_lookup, **kwargs)\n",
    "        self.tgt_vocab = tgt_lookup.get_vocabulary()\n",
    "        self.eos_index = self.tgt_vocab.index(\"<eos>\")\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        return self.model.compile(*args, **kwargs)\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self.model.fit(*args, **kwargs)\n",
    "\n",
    "    def translate(self, sentences, return_alphas=False):\n",
    "        \"\"\"This function takes sentences and returns their translation as a string.\n",
    "        \n",
    "        `sentences` can be either:\n",
    "          - A tf.data.Dataset object\n",
    "          - A list of strings\n",
    "        \"\"\"\n",
    "        if isinstance(sentences, tf.data.Dataset):\n",
    "            inputs = sentences\n",
    "        elif isinstance(sentences, (list, tuple)):\n",
    "            inputs = (\n",
    "                tf.data.Dataset.from_tensor_slices(\n",
    "                    tf.ragged.constant([x.split() for x in sentences])\n",
    "                )\n",
    "                .map(self.src_lookup)\n",
    "                .padded_batch(min(self.batch_size, len(sentences)))\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"'sentences' should be either a tf.Dataset or a list of strings; got: {type(sentences)}\")\n",
    "\n",
    "        outputs, alphas = self.model.predict(inputs, verbose=0)\n",
    "        outputs = tf.math.argmax(outputs, axis=-1).numpy().tolist()\n",
    "        try:\n",
    "            alphas = alphas.numpy().tolist()\n",
    "        except AttributeError:\n",
    "            alphas = alphas.tolist()\n",
    "        generated = []\n",
    "\n",
    "        for y_pred, alpha in zip(outputs, alphas):\n",
    "            try:\n",
    "                eos_idx = y_pred.index(self.eos_index)\n",
    "                del y_pred[eos_idx:]\n",
    "                del alpha[eos_idx:]\n",
    "            except ValueError:\n",
    "                pass\n",
    "            tokens = [self.tgt_vocab[idx] for idx in y_pred if idx > 0]\n",
    "            tokens = \" \".join(tokens)\n",
    "            if return_alphas:\n",
    "                generated.append((tokens, alpha))\n",
    "            else:\n",
    "                generated.append(tokens)\n",
    "\n",
    "        return generated\n",
    "        \n",
    "    def translate_with_attention(self, sentences):\n",
    "        return self.translate(sentences, return_alphas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2660iyt-CutN"
   },
   "source": [
    "The code below shows how this class is supposed to be used (its output will be nonsensical right now, of course, since the model hasn't been trained yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NFiJLKRXCutN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wept exactly dictionary marriage fascinating pilot barking whoever contributions overweight invoice worthwhile moved bald shot choir',\n",
       " 'bored breath rejected give organization celebrating fine earth camera postage downsizing. the by complicated violated confessed']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = Translator(src_lookup, tgt_lookup)\n",
    "# Alternative \"mini\" version of the model for testing:\n",
    "#translator = Translator(src_lookup, tgt_lookup, embedding_dim=32, hidden_dim=64, batch_size=16, max_len=8)\n",
    "translator.translate(['stäng av vattnet .', 'jag älskar friterade bananer .'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cFT9atlCutO"
   },
   "source": [
    "### Evaluation function\n",
    "\n",
    "As mentioned in the lecture, machine translation systems are typically evaluated using the **BLEU metric**. Here we use the implementation of this metric from the `sacrebleu` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "bleu_params = dict(effective_order=True, tokenize=\"none\", force=True, smooth_method=\"floor\", smooth_value=0.01)\n",
    "bleu = BLEU(**bleu_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the test sentence is exactly identical to the reference sentence, the score will be 100 (plus/minus potential floating point rounding errors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000000004"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_score(\"the house is blue .\", [\"the house is blue .\"]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change some words, the score will go down, though never below zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9763536438352522"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_score(\"the house was red .\", [\"the house is blue .\"]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a helper function that takes a trained `Translator` model as well as a `Dataset`, runs all sentences through the translator, and computes the BLEU score for the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bleu(translator, dataset):\n",
    "    hyp = translator.translate(dataset)\n",
    "    ref = [\n",
    "        \" \".join(translator.tgt_vocab[idx] for idx in s if idx not in (0, translator.eos_index))\n",
    "        for s in dataset.unbatch().map(lambda _, x: x).as_numpy_iterator()\n",
    "    ]\n",
    "    return bleu.corpus_score(hyp, [ref]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ozk1hurqCutP"
   },
   "source": [
    "We want to report the BLEU score on the **validation data**, so let's load this as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HNtBMDVqCutP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_dataset = load_translation_dataset(src_lookup, tgt_lookup, \"en-sv-valid.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xe2rPzwmCutQ"
   },
   "source": [
    "### Batching\n",
    "\n",
    "So far we only tested our code on \"batches\" with a single sentence. In order to use larger batches, we need to make sure that all of the sentences in a batch have the same length. We achieve this by _padding_ the shorter sentences to the length of the longest one. Luckily, the `tf.Dataset` class has a function [`padded_batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch) that will do this for us. If we provide a `Dataset` for training, Keras won't shuffle the data automatically, so we also have to [`shuffle`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) the dataset explicitly. (For validation, shuffling doesn't matter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "X-yfmnSzCutQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batched = train_dataset.shuffle(512).padded_batch(64)\n",
    "valid_batched = valid_dataset.padded_batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfM1Ov-sCutQ"
   },
   "source": [
    "### Training\n",
    "\n",
    "Training works as for any other Keras model: we first need to `compile` the model with the optimizer, loss function, and validation metrics that we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yr4VP-SpCutQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=2e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgXElolrCutR"
   },
   "source": [
    "Now it is time to train the system. During training, these diagnostics will be updated periodically: the running average of the training loss; after a full epoch, the loss and the BLEU score on the validation data will be computed and printed.\n",
    "\n",
    "Let's also define a callback that additionally prints the translation of a sample sentence, *jag saknar min familj* (which should translate into *i miss my family*), every 50 batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    keras.callbacks.LambdaCallback(\n",
    "        on_train_batch_end=lambda b, _: tf.print(\" - jag saknar min familj . ->\", translator.translate(['jag saknar min familj .'])[0]) if b > 0 and b % 50 == 0 else None,\n",
    "        on_epoch_end=lambda _, l: l.__setitem__(\"val_bleu\", compute_bleu(translator, valid_batched))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤔 Task 6: Run the model training\n",
    "\n",
    "Run the following code cells that train the model and evaluate it on the validation data.\n",
    "\n",
    "Training the translator takes quite a bit of compute power and time. The default number of epochs is 2; however, you may want to try training for longer, or interrupt the training prematurely and use a partially trained model in case you run out of time.\n",
    "\n",
    "**⚠️ Your submitted notebook must contain output demonstrating at least 20 BLEU points on the validation data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VW8wF8oRCutR",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 50/322 [===>..........................] - ETA: 1:43 - loss: 3.1283 - jag saknar min familj . -> i ' t .\n",
      "100/322 [========>.....................] - ETA: 1:36 - loss: 2.7388 - jag saknar min familj . -> i ' t have to the .\n",
      "150/322 [============>.................] - ETA: 1:10 - loss: 2.4749 - jag saknar min familj . -> i ' m not a lot .\n",
      "200/322 [=================>............] - ETA: 48s - loss: 2.2936 - jag saknar min familj . -> i like my father .\n",
      "250/322 [======================>.......] - ETA: 27s - loss: 2.1436 - jag saknar min familj . -> i like my wife .\n",
      "300/322 [==========================>...] - ETA: 8s - loss: 2.0154 - jag saknar min familj . -> i like my family .\n",
      "322/322 [==============================] - 172s 477ms/step - loss: 1.9661 - val_loss: 4.3045 - val_bleu: 16.7953\n",
      "Epoch 2/2\n",
      " 50/322 [===>..........................] - ETA: 1:48 - loss: 1.2486 - jag saknar min familj . -> i feel my car .\n",
      "100/322 [========>.....................] - ETA: 1:26 - loss: 1.2173 - jag saknar min familj . -> i feel my bag .\n",
      "150/322 [============>.................] - ETA: 1:06 - loss: 1.1746 - jag saknar min familj . -> i feel my family .\n",
      "200/322 [=================>............] - ETA: 46s - loss: 1.1367 - jag saknar min familj . -> i miss my family .\n",
      "250/322 [======================>.......] - ETA: 27s - loss: 1.0897 - jag saknar min familj . -> i miss my family .\n",
      "300/322 [==========================>...] - ETA: 8s - loss: 1.0442 - jag saknar min familj . -> i miss my family .\n",
      "322/322 [==============================] - 132s 409ms/step - loss: 1.0246 - val_loss: 4.5995 - val_bleu: 31.7591\n",
      "CPU times: total: 28min 37s\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    translator.fit(train_batched, epochs=2, validation_data=valid_batched, callbacks=my_callbacks)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.759053723094137"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(translator, valid_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ℹ️ Some notes on the translations\n",
    "\n",
    "If you try out sentences to see their translation (like in the code cell below), you might find some possibly surprising results, such as:\n",
    "\n",
    "- **Translations that are seemingly nonsensical or have nothing to do with the input.** This might be because the model is undertrained; you could try training for more epochs to see if the translations improve. It's also possible that you tried words or phrases that were just not well-represented in the training data.\n",
    "- **Translations that have a lot of `<unk>`s.** This might be due to the words just not being present in the model's vocabulary! Remember you can check this with the vocabularies you created, e.g. `\"friterade\" in src_vocab`. You could try increasing the vocabulary size and see if the results improve, but this will also increase training time.\n",
    "\n",
    "Finally, keep in mind that both the dataset and the model itself is quite tiny, as it's optimized for speed and demonstration purposes rather than efficiency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i miss my family .', 'close the water .', 'i love <unk> .']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate(['jag saknar min familj . ', 'stäng av vattnet .', 'jag älskar friterade bananer .'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7677Q0QLCutS"
   },
   "source": [
    "# Part 4: Visualising attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCzHCB4XCutS"
   },
   "source": [
    "Figure&nbsp;3 in the paper by [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473) shows some heatmaps of attention weights in selected sentences. In the last problem of this lab, we ask you to inspect attention weights for your trained translation system. We define a function `plot_attention` that visualises the attention weights. The *x*-axis corresponds to the words in the source sentence (Swedish) and the *y*-axis to the generated target sentence (English).\n",
    "\n",
    "The heatmap colours represent the **strengths of the attention weights**, with _lighter_ cells indicating a _higher_ attention value, just as in the Bahdanau et al. paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "IXHPiuamCutS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def plot_attention(translator, sentence):\n",
    "    translation, weights = translator.translate_with_attention([sentence])[0]\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(weights, cmap='Blues_r', vmin=0., vmax=1.)\n",
    "\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xticks(np.arange(weights.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(weights.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticklabels(sentence.split(), minor=False, rotation=40)\n",
    "    ax.set_yticklabels(translation.split(), minor=False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGCwchIdCutS"
   },
   "source": [
    "Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Hj4teeITCutT"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"378.2701pt\" height=\"315.875785pt\" viewBox=\"0 0 378.2701 315.875785\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-14T20:05:19.401181</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 315.875785 \n",
       "L 378.2701 315.875785 \n",
       "L 378.2701 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 36.8125 303.109379 \n",
       "L 322.5085 303.109379 \n",
       "L 322.5085 36.997379 \n",
       "L 36.8125 36.997379 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 65.3821 303.109379 \n",
       "L 65.3821 36.997379 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\"/>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- jag -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(61.89519 31.885095) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-6a\" d=\"M 419 3928 \n",
       "L 419 4581 \n",
       "L 981 4581 \n",
       "L 981 3928 \n",
       "L 419 3928 \n",
       "z\n",
       "M -294 -1288 \n",
       "L -188 -809 \n",
       "Q -19 -853 78 -853 \n",
       "Q 250 -853 334 -739 \n",
       "Q 419 -625 419 -169 \n",
       "L 419 3319 \n",
       "L 981 3319 \n",
       "L 981 -181 \n",
       "Q 981 -794 822 -1034 \n",
       "Q 619 -1347 147 -1347 \n",
       "Q -81 -1347 -294 -1288 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-67\" d=\"M 319 -275 \n",
       "L 866 -356 \n",
       "Q 900 -609 1056 -725 \n",
       "Q 1266 -881 1628 -881 \n",
       "Q 2019 -881 2231 -725 \n",
       "Q 2444 -569 2519 -288 \n",
       "Q 2563 -116 2559 434 \n",
       "Q 2191 0 1641 0 \n",
       "Q 956 0 581 494 \n",
       "Q 206 988 206 1678 \n",
       "Q 206 2153 378 2554 \n",
       "Q 550 2956 876 3175 \n",
       "Q 1203 3394 1644 3394 \n",
       "Q 2231 3394 2613 2919 \n",
       "L 2613 3319 \n",
       "L 3131 3319 \n",
       "L 3131 450 \n",
       "Q 3131 -325 2973 -648 \n",
       "Q 2816 -972 2473 -1159 \n",
       "Q 2131 -1347 1631 -1347 \n",
       "Q 1038 -1347 672 -1080 \n",
       "Q 306 -813 319 -275 \n",
       "z\n",
       "M 784 1719 \n",
       "Q 784 1066 1043 766 \n",
       "Q 1303 466 1694 466 \n",
       "Q 2081 466 2343 764 \n",
       "Q 2606 1063 2606 1700 \n",
       "Q 2606 2309 2336 2618 \n",
       "Q 2066 2928 1684 2928 \n",
       "Q 1309 2928 1046 2623 \n",
       "Q 784 2319 784 1719 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-6a\"/>\n",
       "       <use xlink:href=\"#ArialMT-61\" x=\"22.216797\"/>\n",
       "       <use xlink:href=\"#ArialMT-67\" x=\"77.832031\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 122.5213 303.109379 \n",
       "L 122.5213 36.997379 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\"/>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- saknar -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(112.687552 31.974866) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-6b\" d=\"M 425 0 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 1969 \n",
       "L 2319 3319 \n",
       "L 3047 3319 \n",
       "L 1778 2088 \n",
       "L 3175 0 \n",
       "L 2481 0 \n",
       "L 1384 1697 \n",
       "L 988 1316 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-73\"/>\n",
       "       <use xlink:href=\"#ArialMT-61\" x=\"50\"/>\n",
       "       <use xlink:href=\"#ArialMT-6b\" x=\"105.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-6e\" x=\"155.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-61\" x=\"211.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-72\" x=\"266.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 179.6605 303.109379 \n",
       "L 179.6605 36.997379 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\"/>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- min -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(175.150761 31.974866) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 925 3319 \n",
       "L 925 2853 \n",
       "Q 1081 3097 1340 3245 \n",
       "Q 1600 3394 1931 3394 \n",
       "Q 2300 3394 2536 3241 \n",
       "Q 2772 3088 2869 2813 \n",
       "Q 3263 3394 3894 3394 \n",
       "Q 4388 3394 4653 3120 \n",
       "Q 4919 2847 4919 2278 \n",
       "L 4919 0 \n",
       "L 4359 0 \n",
       "L 4359 2091 \n",
       "Q 4359 2428 4304 2576 \n",
       "Q 4250 2725 4106 2815 \n",
       "Q 3963 2906 3769 2906 \n",
       "Q 3419 2906 3187 2673 \n",
       "Q 2956 2441 2956 1928 \n",
       "L 2956 0 \n",
       "L 2394 0 \n",
       "L 2394 2156 \n",
       "Q 2394 2531 2256 2718 \n",
       "Q 2119 2906 1806 2906 \n",
       "Q 1569 2906 1367 2781 \n",
       "Q 1166 2656 1075 2415 \n",
       "Q 984 2175 984 1722 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-6d\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" x=\"83.300781\"/>\n",
       "       <use xlink:href=\"#ArialMT-6e\" x=\"105.517578\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 236.7997 303.109379 \n",
       "L 236.7997 36.997379 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\"/>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- familj -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(229.525329 31.885095) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-66\" d=\"M 556 0 \n",
       "L 556 2881 \n",
       "L 59 2881 \n",
       "L 59 3319 \n",
       "L 556 3319 \n",
       "L 556 3672 \n",
       "Q 556 4006 616 4169 \n",
       "Q 697 4388 901 4523 \n",
       "Q 1106 4659 1475 4659 \n",
       "Q 1713 4659 2000 4603 \n",
       "L 1916 4113 \n",
       "Q 1741 4144 1584 4144 \n",
       "Q 1328 4144 1222 4034 \n",
       "Q 1116 3925 1116 3625 \n",
       "L 1116 3319 \n",
       "L 1763 3319 \n",
       "L 1763 2881 \n",
       "L 1116 2881 \n",
       "L 1116 0 \n",
       "L 556 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-66\"/>\n",
       "       <use xlink:href=\"#ArialMT-61\" x=\"27.783203\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" x=\"166.699219\"/>\n",
       "       <use xlink:href=\"#ArialMT-6c\" x=\"188.916016\"/>\n",
       "       <use xlink:href=\"#ArialMT-6a\" x=\"211.132812\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 293.9389 303.109379 \n",
       "L 293.9389 36.997379 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\"/>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- . -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(294.536523 31.974866) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
       "L 581 641 \n",
       "L 1222 641 \n",
       "L 1222 0 \n",
       "L 581 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-2e\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 36.8125 63.608579 \n",
       "L 322.5085 63.608579 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\"/>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- i -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(31.090625 67.187485) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-69\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 36.8125 116.830979 \n",
       "L 322.5085 116.830979 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\"/>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- miss -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(12.760938 120.409885) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-6d\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" x=\"83.300781\"/>\n",
       "       <use xlink:href=\"#ArialMT-73\" x=\"105.517578\"/>\n",
       "       <use xlink:href=\"#ArialMT-73\" x=\"155.517578\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 36.8125 170.053379 \n",
       "L 322.5085 170.053379 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\"/>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- my -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(19.982813 173.573691) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-79\" d=\"M 397 -1278 \n",
       "L 334 -750 \n",
       "Q 519 -800 656 -800 \n",
       "Q 844 -800 956 -737 \n",
       "Q 1069 -675 1141 -563 \n",
       "Q 1194 -478 1313 -144 \n",
       "Q 1328 -97 1363 -6 \n",
       "L 103 3319 \n",
       "L 709 3319 \n",
       "L 1400 1397 \n",
       "Q 1534 1031 1641 628 \n",
       "Q 1738 1016 1872 1384 \n",
       "L 2581 3319 \n",
       "L 3144 3319 \n",
       "L 1881 -56 \n",
       "Q 1678 -603 1566 -809 \n",
       "Q 1416 -1088 1222 -1217 \n",
       "Q 1028 -1347 759 -1347 \n",
       "Q 597 -1347 397 -1278 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-6d\"/>\n",
       "       <use xlink:href=\"#ArialMT-79\" x=\"83.300781\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 36.8125 223.275779 \n",
       "L 322.5085 223.275779 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\"/>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- family -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 226.915623) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-66\"/>\n",
       "       <use xlink:href=\"#ArialMT-61\" x=\"27.783203\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" x=\"166.699219\"/>\n",
       "       <use xlink:href=\"#ArialMT-6c\" x=\"188.916016\"/>\n",
       "       <use xlink:href=\"#ArialMT-79\" x=\"211.132812\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 36.8125 276.498179 \n",
       "L 322.5085 276.498179 \n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\"/>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- . -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(30.534375 280.077085) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-2e\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyQuadMesh_1\">\n",
       "    <path d=\"M 36.8125 36.997379 \n",
       "L 36.8125 90.219779 \n",
       "L 93.9517 90.219779 \n",
       "L 93.9517 36.997379 \n",
       "L 36.8125 36.997379 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #f5fafe\"/>\n",
       "    <path d=\"M 93.9517 36.997379 \n",
       "L 93.9517 90.219779 \n",
       "L 151.0909 90.219779 \n",
       "L 151.0909 36.997379 \n",
       "L 93.9517 36.997379 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08316d\"/>\n",
       "    <path d=\"M 151.0909 36.997379 \n",
       "L 151.0909 90.219779 \n",
       "L 208.2301 90.219779 \n",
       "L 208.2301 36.997379 \n",
       "L 151.0909 36.997379 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 208.2301 36.997379 \n",
       "L 208.2301 90.219779 \n",
       "L 265.3693 90.219779 \n",
       "L 265.3693 36.997379 \n",
       "L 208.2301 36.997379 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 265.3693 36.997379 \n",
       "L 265.3693 90.219779 \n",
       "L 322.5085 90.219779 \n",
       "L 322.5085 36.997379 \n",
       "L 265.3693 36.997379 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 36.8125 90.219779 \n",
       "L 36.8125 143.442179 \n",
       "L 93.9517 143.442179 \n",
       "L 93.9517 90.219779 \n",
       "L 36.8125 90.219779 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08326e\"/>\n",
       "    <path d=\"M 93.9517 90.219779 \n",
       "L 93.9517 143.442179 \n",
       "L 151.0909 143.442179 \n",
       "L 151.0909 90.219779 \n",
       "L 93.9517 90.219779 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #f2f7fd\"/>\n",
       "    <path d=\"M 151.0909 90.219779 \n",
       "L 151.0909 143.442179 \n",
       "L 208.2301 143.442179 \n",
       "L 208.2301 90.219779 \n",
       "L 151.0909 90.219779 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #083471\"/>\n",
       "    <path d=\"M 208.2301 90.219779 \n",
       "L 208.2301 143.442179 \n",
       "L 265.3693 143.442179 \n",
       "L 265.3693 90.219779 \n",
       "L 208.2301 90.219779 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 265.3693 90.219779 \n",
       "L 265.3693 143.442179 \n",
       "L 322.5085 143.442179 \n",
       "L 322.5085 90.219779 \n",
       "L 265.3693 90.219779 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 36.8125 143.442179 \n",
       "L 36.8125 196.664579 \n",
       "L 93.9517 196.664579 \n",
       "L 93.9517 143.442179 \n",
       "L 36.8125 143.442179 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08316d\"/>\n",
       "    <path d=\"M 93.9517 143.442179 \n",
       "L 93.9517 196.664579 \n",
       "L 151.0909 196.664579 \n",
       "L 151.0909 143.442179 \n",
       "L 93.9517 143.442179 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #0a539e\"/>\n",
       "    <path d=\"M 151.0909 143.442179 \n",
       "L 151.0909 196.664579 \n",
       "L 208.2301 196.664579 \n",
       "L 208.2301 143.442179 \n",
       "L 151.0909 143.442179 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #aed1e7\"/>\n",
       "    <path d=\"M 208.2301 143.442179 \n",
       "L 208.2301 196.664579 \n",
       "L 265.3693 196.664579 \n",
       "L 265.3693 143.442179 \n",
       "L 208.2301 143.442179 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #125ea6\"/>\n",
       "    <path d=\"M 265.3693 143.442179 \n",
       "L 265.3693 196.664579 \n",
       "L 322.5085 196.664579 \n",
       "L 322.5085 143.442179 \n",
       "L 265.3693 143.442179 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08316d\"/>\n",
       "    <path d=\"M 36.8125 196.664579 \n",
       "L 36.8125 249.886979 \n",
       "L 93.9517 249.886979 \n",
       "L 93.9517 196.664579 \n",
       "L 36.8125 196.664579 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 93.9517 196.664579 \n",
       "L 93.9517 249.886979 \n",
       "L 151.0909 249.886979 \n",
       "L 151.0909 196.664579 \n",
       "L 93.9517 196.664579 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 151.0909 196.664579 \n",
       "L 151.0909 249.886979 \n",
       "L 208.2301 249.886979 \n",
       "L 208.2301 196.664579 \n",
       "L 151.0909 196.664579 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #083471\"/>\n",
       "    <path d=\"M 208.2301 196.664579 \n",
       "L 208.2301 249.886979 \n",
       "L 265.3693 249.886979 \n",
       "L 265.3693 196.664579 \n",
       "L 208.2301 196.664579 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #eef5fc\"/>\n",
       "    <path d=\"M 265.3693 196.664579 \n",
       "L 265.3693 249.886979 \n",
       "L 322.5085 249.886979 \n",
       "L 322.5085 196.664579 \n",
       "L 265.3693 196.664579 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #083674\"/>\n",
       "    <path d=\"M 36.8125 249.886979 \n",
       "L 36.8125 303.109379 \n",
       "L 93.9517 303.109379 \n",
       "L 93.9517 249.886979 \n",
       "L 36.8125 249.886979 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08509b\"/>\n",
       "    <path d=\"M 93.9517 249.886979 \n",
       "L 93.9517 303.109379 \n",
       "L 151.0909 303.109379 \n",
       "L 151.0909 249.886979 \n",
       "L 93.9517 249.886979 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #08519c\"/>\n",
       "    <path d=\"M 151.0909 249.886979 \n",
       "L 151.0909 303.109379 \n",
       "L 208.2301 303.109379 \n",
       "L 208.2301 249.886979 \n",
       "L 151.0909 249.886979 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #0a549e\"/>\n",
       "    <path d=\"M 208.2301 249.886979 \n",
       "L 208.2301 303.109379 \n",
       "L 265.3693 303.109379 \n",
       "L 265.3693 249.886979 \n",
       "L 208.2301 249.886979 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #1562a9\"/>\n",
       "    <path d=\"M 265.3693 249.886979 \n",
       "L 265.3693 303.109379 \n",
       "L 322.5085 303.109379 \n",
       "L 322.5085 249.886979 \n",
       "L 265.3693 249.886979 \n",
       "z\n",
       "\" clip-path=\"url(#pef67c69700)\" style=\"fill: #519ccc\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 36.8125 303.109379 \n",
       "L 36.8125 36.997379 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 322.5085 303.109379 \n",
       "L 322.5085 36.997379 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 36.8125 303.109379 \n",
       "L 322.5085 303.109379 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 36.8125 36.997379 \n",
       "L 322.5085 36.997379 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 340.3645 303.109379 \n",
       "L 353.6701 303.109379 \n",
       "L 353.6701 36.997379 \n",
       "L 340.3645 36.997379 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\"/>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_21\"/>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(357.1701 306.688285) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_22\"/>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(357.1701 253.465885) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_23\"/>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.4 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(357.1701 200.243485) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_24\"/>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.6 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(357.1701 147.021085) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_25\"/>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.8 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(357.1701 93.798685) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_26\"/>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(357.1701 40.576285) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAABIAAAFxCAYAAAB+2fgXAAABuklEQVR4nO2bwY3DMAwEZcOPKyd9pf93roTlY2AMiN0CBlqtSMoKcv19vr8D6DnXTXAOQznnPOe6KFCtZRCzInKPai2Dai2DfNVP7dHd+INqLctnTVm0tZZBPmuyk73YmjJ+yNqli59a0XMYjtHa4tQa/3ugWsvCzpHQmi61Fm1WrWW1aN8EtWijai2rRTsCIRznHmGgtdZu3cN4U5uA1vZs3R7VWlatjUCykb34NlJrWZ0iI1DjzyCEA1q791rDUoMu/kZrXPVDLwjkyYZAi3s2Vf1Ca00tg6AFGRtbe3aU0Nrm1BBMe/ZEQmtNLQq8+lGgxY1t8fUYtMaAhJ/r1JKE/WjxkwZ2shePI1+rpd5GhNZ0U0S4R7rGpoyfAZF3yE6RDFq8R3utUSDfzX/zIwsGso3snuwsMn6bNV1qyt9FIBB1rRFa8/0E3dTeBOn2iPs60llrahnkswamBoEW37OFf83b+6TR1AYgW/Ub/77Ynp3U1LJ8qbWxZXUcZTW1AaiNbQBiOB1HAzW1AaiNbQDSWTtNLYOE1qDUwOpnpOzZtnHU1AYgXWrCNuJbUcdRBPWbNmpxaosb2z8DGwjO1q+hpAAAAABJRU5ErkJggg==\" id=\"imagee9aef628c0\" transform=\"scale(1 -1) translate(0 -265.68)\" x=\"340.56\" y=\"-36.72\" width=\"12.96\" height=\"265.68\"/>\n",
       "   <g id=\"LineCollection_1\"/>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 340.3645 303.109379 \n",
       "L 347.0173 303.109379 \n",
       "L 353.6701 303.109379 \n",
       "L 353.6701 36.997379 \n",
       "L 347.0173 36.997379 \n",
       "L 340.3645 36.997379 \n",
       "L 340.3645 303.109379 \n",
       "z\n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pef67c69700\">\n",
       "   <rect x=\"36.8125\" y=\"36.997379\" width=\"285.696\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(translator, 'jag saknar min familj . ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"394.962288pt\" height=\"313.106156pt\" viewBox=\"0 0 394.962288 313.106156\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-14T20:05:25.445946</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 313.106156 \n",
       "L 394.962288 313.106156 \n",
       "L 394.962288 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 53.504688 300.339749 \n",
       "L 339.200688 300.339749 \n",
       "L 339.200688 34.227749 \n",
       "L 53.504688 34.227749 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 82.074288 300.339749 \n",
       "L 82.074288 34.227749 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\"/>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- jag -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(78.587378 29.115465) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-6a\" d=\"M 419 3928 \n",
       "L 419 4581 \n",
       "L 981 4581 \n",
       "L 981 3928 \n",
       "L 419 3928 \n",
       "z\n",
       "M -294 -1288 \n",
       "L -188 -809 \n",
       "Q -19 -853 78 -853 \n",
       "Q 250 -853 334 -739 \n",
       "Q 419 -625 419 -169 \n",
       "L 419 3319 \n",
       "L 981 3319 \n",
       "L 981 -181 \n",
       "Q 981 -794 822 -1034 \n",
       "Q 619 -1347 147 -1347 \n",
       "Q -81 -1347 -294 -1288 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-67\" d=\"M 319 -275 \n",
       "L 866 -356 \n",
       "Q 900 -609 1056 -725 \n",
       "Q 1266 -881 1628 -881 \n",
       "Q 2019 -881 2231 -725 \n",
       "Q 2444 -569 2519 -288 \n",
       "Q 2563 -116 2559 434 \n",
       "Q 2191 0 1641 0 \n",
       "Q 956 0 581 494 \n",
       "Q 206 988 206 1678 \n",
       "Q 206 2153 378 2554 \n",
       "Q 550 2956 876 3175 \n",
       "Q 1203 3394 1644 3394 \n",
       "Q 2231 3394 2613 2919 \n",
       "L 2613 3319 \n",
       "L 3131 3319 \n",
       "L 3131 450 \n",
       "Q 3131 -325 2973 -648 \n",
       "Q 2816 -972 2473 -1159 \n",
       "Q 2131 -1347 1631 -1347 \n",
       "Q 1038 -1347 672 -1080 \n",
       "Q 306 -813 319 -275 \n",
       "z\n",
       "M 784 1719 \n",
       "Q 784 1066 1043 766 \n",
       "Q 1303 466 1694 466 \n",
       "Q 2081 466 2343 764 \n",
       "Q 2606 1063 2606 1700 \n",
       "Q 2606 2309 2336 2618 \n",
       "Q 2066 2928 1684 2928 \n",
       "Q 1309 2928 1046 2623 \n",
       "Q 784 2319 784 1719 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-6a\"/>\n",
       "       <use xlink:href=\"#ArialMT-61\" x=\"22.216797\"/>\n",
       "       <use xlink:href=\"#ArialMT-67\" x=\"77.832031\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 139.213488 300.339749 \n",
       "L 139.213488 34.227749 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\"/>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- köpte -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(131.520172 29.205236) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-6b\" d=\"M 425 0 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 1969 \n",
       "L 2319 3319 \n",
       "L 3047 3319 \n",
       "L 1778 2088 \n",
       "L 3175 0 \n",
       "L 2481 0 \n",
       "L 1384 1697 \n",
       "L 988 1316 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-f6\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "M 891 3969 \n",
       "L 891 4609 \n",
       "L 1478 4609 \n",
       "L 1478 3969 \n",
       "L 891 3969 \n",
       "z\n",
       "M 2056 3969 \n",
       "L 2056 4609 \n",
       "L 2644 4609 \n",
       "L 2644 3969 \n",
       "L 2056 3969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
       "L 1731 6 \n",
       "Q 1494 -44 1306 -44 \n",
       "Q 1000 -44 831 53 \n",
       "Q 663 150 594 308 \n",
       "Q 525 466 525 972 \n",
       "L 525 2881 \n",
       "L 113 2881 \n",
       "L 113 3319 \n",
       "L 525 3319 \n",
       "L 525 4141 \n",
       "L 1084 4478 \n",
       "L 1084 3319 \n",
       "L 1650 3319 \n",
       "L 1650 2881 \n",
       "L 1084 2881 \n",
       "L 1084 941 \n",
       "Q 1084 700 1114 631 \n",
       "Q 1144 563 1211 522 \n",
       "Q 1278 481 1403 481 \n",
       "Q 1497 481 1650 503 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-6b\"/>\n",
       "       <use xlink:href=\"#ArialMT-f6\" x=\"50\"/>\n",
       "       <use xlink:href=\"#ArialMT-70\" x=\"105.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-74\" x=\"161.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" x=\"189.013672\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 196.352688 300.339749 \n",
       "L 196.352688 34.227749 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\"/>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- lite -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(193.118293 29.205236) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-6c\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" x=\"22.216797\"/>\n",
       "       <use xlink:href=\"#ArialMT-74\" x=\"44.433594\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" x=\"72.216797\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 253.491888 300.339749 \n",
       "L 253.491888 34.227749 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\"/>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- grejer -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(245.324327 29.115465) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-67\"/>\n",
       "       <use xlink:href=\"#ArialMT-72\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" x=\"88.916016\"/>\n",
       "       <use xlink:href=\"#ArialMT-6a\" x=\"144.53125\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" x=\"166.748047\"/>\n",
       "       <use xlink:href=\"#ArialMT-72\" x=\"222.363281\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 310.631088 300.339749 \n",
       "L 310.631088 34.227749 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\"/>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- . -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(311.22871 29.205236) rotate(-40) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
       "L 581 641 \n",
       "L 1222 641 \n",
       "L 1222 0 \n",
       "L 581 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-2e\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 53.504688 60.838949 \n",
       "L 339.200688 60.838949 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\"/>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- i -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(47.782813 64.417856) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-69\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 53.504688 114.061349 \n",
       "L 339.200688 114.061349 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\"/>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- bought -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(19.421875 117.640256) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-62\" d=\"M 941 0 \n",
       "L 419 0 \n",
       "L 419 4581 \n",
       "L 981 4581 \n",
       "L 981 2947 \n",
       "Q 1338 3394 1891 3394 \n",
       "Q 2197 3394 2470 3270 \n",
       "Q 2744 3147 2920 2923 \n",
       "Q 3097 2700 3197 2384 \n",
       "Q 3297 2069 3297 1709 \n",
       "Q 3297 856 2875 390 \n",
       "Q 2453 -75 1863 -75 \n",
       "Q 1275 -75 941 416 \n",
       "L 941 0 \n",
       "z\n",
       "M 934 1684 \n",
       "Q 934 1088 1097 822 \n",
       "Q 1363 388 1816 388 \n",
       "Q 2184 388 2453 708 \n",
       "Q 2722 1028 2722 1663 \n",
       "Q 2722 2313 2464 2622 \n",
       "Q 2206 2931 1841 2931 \n",
       "Q 1472 2931 1203 2611 \n",
       "Q 934 2291 934 1684 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-75\" d=\"M 2597 0 \n",
       "L 2597 488 \n",
       "Q 2209 -75 1544 -75 \n",
       "Q 1250 -75 995 37 \n",
       "Q 741 150 617 320 \n",
       "Q 494 491 444 738 \n",
       "Q 409 903 409 1263 \n",
       "L 409 3319 \n",
       "L 972 3319 \n",
       "L 972 1478 \n",
       "Q 972 1038 1006 884 \n",
       "Q 1059 663 1231 536 \n",
       "Q 1403 409 1656 409 \n",
       "Q 1909 409 2131 539 \n",
       "Q 2353 669 2445 892 \n",
       "Q 2538 1116 2538 1541 \n",
       "L 2538 3319 \n",
       "L 3100 3319 \n",
       "L 3100 0 \n",
       "L 2597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-68\" d=\"M 422 0 \n",
       "L 422 4581 \n",
       "L 984 4581 \n",
       "L 984 2938 \n",
       "Q 1378 3394 1978 3394 \n",
       "Q 2347 3394 2619 3248 \n",
       "Q 2891 3103 3008 2847 \n",
       "Q 3125 2591 3125 2103 \n",
       "L 3125 0 \n",
       "L 2563 0 \n",
       "L 2563 2103 \n",
       "Q 2563 2525 2380 2717 \n",
       "Q 2197 2909 1863 2909 \n",
       "Q 1613 2909 1392 2779 \n",
       "Q 1172 2650 1078 2428 \n",
       "Q 984 2206 984 1816 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-62\"/>\n",
       "       <use xlink:href=\"#ArialMT-6f\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-67\" x=\"166.845703\"/>\n",
       "       <use xlink:href=\"#ArialMT-68\" x=\"222.460938\"/>\n",
       "       <use xlink:href=\"#ArialMT-74\" x=\"278.076172\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 53.504688 167.283749 \n",
       "L 339.200688 167.283749 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\"/>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- some -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(25.553125 170.862656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 925 3319 \n",
       "L 925 2853 \n",
       "Q 1081 3097 1340 3245 \n",
       "Q 1600 3394 1931 3394 \n",
       "Q 2300 3394 2536 3241 \n",
       "Q 2772 3088 2869 2813 \n",
       "Q 3263 3394 3894 3394 \n",
       "Q 4388 3394 4653 3120 \n",
       "Q 4919 2847 4919 2278 \n",
       "L 4919 0 \n",
       "L 4359 0 \n",
       "L 4359 2091 \n",
       "Q 4359 2428 4304 2576 \n",
       "Q 4250 2725 4106 2815 \n",
       "Q 3963 2906 3769 2906 \n",
       "Q 3419 2906 3187 2673 \n",
       "Q 2956 2441 2956 1928 \n",
       "L 2956 0 \n",
       "L 2394 0 \n",
       "L 2394 2156 \n",
       "Q 2394 2531 2256 2718 \n",
       "Q 2119 2906 1806 2906 \n",
       "Q 1569 2906 1367 2781 \n",
       "Q 1166 2656 1075 2415 \n",
       "Q 984 2175 984 1722 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-73\"/>\n",
       "       <use xlink:href=\"#ArialMT-6f\" x=\"50\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" x=\"105.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" x=\"188.916016\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 53.504688 220.506149 \n",
       "L 339.200688 220.506149 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\"/>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- questions -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 224.085056) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-71\" d=\"M 2538 -1272 \n",
       "L 2538 353 \n",
       "Q 2406 169 2170 47 \n",
       "Q 1934 -75 1669 -75 \n",
       "Q 1078 -75 651 397 \n",
       "Q 225 869 225 1691 \n",
       "Q 225 2191 398 2587 \n",
       "Q 572 2984 901 3189 \n",
       "Q 1231 3394 1625 3394 \n",
       "Q 2241 3394 2594 2875 \n",
       "L 2594 3319 \n",
       "L 3100 3319 \n",
       "L 3100 -1272 \n",
       "L 2538 -1272 \n",
       "z\n",
       "M 803 1669 \n",
       "Q 803 1028 1072 708 \n",
       "Q 1341 388 1716 388 \n",
       "Q 2075 388 2334 692 \n",
       "Q 2594 997 2594 1619 \n",
       "Q 2594 2281 2320 2615 \n",
       "Q 2047 2950 1678 2950 \n",
       "Q 1313 2950 1058 2639 \n",
       "Q 803 2328 803 1669 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-71\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-73\" x=\"166.845703\"/>\n",
       "       <use xlink:href=\"#ArialMT-74\" x=\"216.845703\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" x=\"244.628906\"/>\n",
       "       <use xlink:href=\"#ArialMT-6f\" x=\"266.845703\"/>\n",
       "       <use xlink:href=\"#ArialMT-6e\" x=\"322.460938\"/>\n",
       "       <use xlink:href=\"#ArialMT-73\" x=\"378.076172\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 53.504688 273.728549 \n",
       "L 339.200688 273.728549 \n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: none; stroke: #cccccc; stroke-width: 0.8; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\"/>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- . -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(47.226562 277.307456) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-2e\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyQuadMesh_1\">\n",
       "    <path d=\"M 53.504688 34.227749 \n",
       "L 53.504688 87.450149 \n",
       "L 110.643888 87.450149 \n",
       "L 110.643888 34.227749 \n",
       "L 53.504688 34.227749 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #f6faff\"/>\n",
       "    <path d=\"M 110.643888 34.227749 \n",
       "L 110.643888 87.450149 \n",
       "L 167.783088 87.450149 \n",
       "L 167.783088 34.227749 \n",
       "L 110.643888 34.227749 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 167.783088 34.227749 \n",
       "L 167.783088 87.450149 \n",
       "L 224.922288 87.450149 \n",
       "L 224.922288 34.227749 \n",
       "L 167.783088 34.227749 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 224.922288 34.227749 \n",
       "L 224.922288 87.450149 \n",
       "L 282.061488 87.450149 \n",
       "L 282.061488 34.227749 \n",
       "L 224.922288 34.227749 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 282.061488 34.227749 \n",
       "L 282.061488 87.450149 \n",
       "L 339.200688 87.450149 \n",
       "L 339.200688 34.227749 \n",
       "L 282.061488 34.227749 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 53.504688 87.450149 \n",
       "L 53.504688 140.672549 \n",
       "L 110.643888 140.672549 \n",
       "L 110.643888 87.450149 \n",
       "L 53.504688 87.450149 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #083b7c\"/>\n",
       "    <path d=\"M 110.643888 87.450149 \n",
       "L 110.643888 140.672549 \n",
       "L 167.783088 140.672549 \n",
       "L 167.783088 87.450149 \n",
       "L 110.643888 87.450149 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #e7f0fa\"/>\n",
       "    <path d=\"M 167.783088 87.450149 \n",
       "L 167.783088 140.672549 \n",
       "L 224.922288 140.672549 \n",
       "L 224.922288 87.450149 \n",
       "L 167.783088 87.450149 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #083979\"/>\n",
       "    <path d=\"M 224.922288 87.450149 \n",
       "L 224.922288 140.672549 \n",
       "L 282.061488 140.672549 \n",
       "L 282.061488 87.450149 \n",
       "L 224.922288 87.450149 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 282.061488 87.450149 \n",
       "L 282.061488 140.672549 \n",
       "L 339.200688 140.672549 \n",
       "L 339.200688 87.450149 \n",
       "L 282.061488 87.450149 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 53.504688 140.672549 \n",
       "L 53.504688 193.894949 \n",
       "L 110.643888 193.894949 \n",
       "L 110.643888 140.672549 \n",
       "L 53.504688 140.672549 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 110.643888 140.672549 \n",
       "L 110.643888 193.894949 \n",
       "L 167.783088 193.894949 \n",
       "L 167.783088 140.672549 \n",
       "L 110.643888 140.672549 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #083979\"/>\n",
       "    <path d=\"M 167.783088 140.672549 \n",
       "L 167.783088 193.894949 \n",
       "L 224.922288 193.894949 \n",
       "L 224.922288 140.672549 \n",
       "L 167.783088 140.672549 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #e6f0f9\"/>\n",
       "    <path d=\"M 224.922288 140.672549 \n",
       "L 224.922288 193.894949 \n",
       "L 282.061488 193.894949 \n",
       "L 282.061488 140.672549 \n",
       "L 224.922288 140.672549 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #083b7c\"/>\n",
       "    <path d=\"M 282.061488 140.672549 \n",
       "L 282.061488 193.894949 \n",
       "L 339.200688 193.894949 \n",
       "L 339.200688 140.672549 \n",
       "L 282.061488 140.672549 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 53.504688 193.894949 \n",
       "L 53.504688 247.117349 \n",
       "L 110.643888 247.117349 \n",
       "L 110.643888 193.894949 \n",
       "L 53.504688 193.894949 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 110.643888 193.894949 \n",
       "L 110.643888 247.117349 \n",
       "L 167.783088 247.117349 \n",
       "L 167.783088 193.894949 \n",
       "L 110.643888 193.894949 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08306b\"/>\n",
       "    <path d=\"M 167.783088 193.894949 \n",
       "L 167.783088 247.117349 \n",
       "L 224.922288 247.117349 \n",
       "L 224.922288 193.894949 \n",
       "L 167.783088 193.894949 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #0d57a1\"/>\n",
       "    <path d=\"M 224.922288 193.894949 \n",
       "L 224.922288 247.117349 \n",
       "L 282.061488 247.117349 \n",
       "L 282.061488 193.894949 \n",
       "L 224.922288 193.894949 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #d7e6f5\"/>\n",
       "    <path d=\"M 282.061488 193.894949 \n",
       "L 282.061488 247.117349 \n",
       "L 339.200688 247.117349 \n",
       "L 339.200688 193.894949 \n",
       "L 282.061488 193.894949 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08326e\"/>\n",
       "    <path d=\"M 53.504688 247.117349 \n",
       "L 53.504688 300.339749 \n",
       "L 110.643888 300.339749 \n",
       "L 110.643888 247.117349 \n",
       "L 53.504688 247.117349 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08316d\"/>\n",
       "    <path d=\"M 110.643888 247.117349 \n",
       "L 110.643888 300.339749 \n",
       "L 167.783088 300.339749 \n",
       "L 167.783088 247.117349 \n",
       "L 110.643888 247.117349 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #08316d\"/>\n",
       "    <path d=\"M 167.783088 247.117349 \n",
       "L 167.783088 300.339749 \n",
       "L 224.922288 300.339749 \n",
       "L 224.922288 247.117349 \n",
       "L 167.783088 247.117349 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #083979\"/>\n",
       "    <path d=\"M 224.922288 247.117349 \n",
       "L 224.922288 300.339749 \n",
       "L 282.061488 300.339749 \n",
       "L 282.061488 247.117349 \n",
       "L 224.922288 247.117349 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #dae8f6\"/>\n",
       "    <path d=\"M 282.061488 247.117349 \n",
       "L 282.061488 300.339749 \n",
       "L 339.200688 300.339749 \n",
       "L 339.200688 247.117349 \n",
       "L 282.061488 247.117349 \n",
       "z\n",
       "\" clip-path=\"url(#pcb0c6a0f94)\" style=\"fill: #084990\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 53.504688 300.339749 \n",
       "L 53.504688 34.227749 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 339.200688 300.339749 \n",
       "L 339.200688 34.227749 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 53.504688 300.339749 \n",
       "L 339.200688 300.339749 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 53.504688 34.227749 \n",
       "L 339.200688 34.227749 \n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 357.056688 300.339749 \n",
       "L 370.362288 300.339749 \n",
       "L 370.362288 34.227749 \n",
       "L 357.056688 34.227749 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\"/>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_21\"/>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(373.862288 303.918656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_22\"/>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(373.862288 250.696256) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_23\"/>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.4 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(373.862288 197.473856) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_24\"/>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.6 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(373.862288 144.251456) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_25\"/>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.8 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(373.862288 91.029056) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_26\"/>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(373.862288 37.806656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAABIAAAFxCAYAAAB+2fgXAAABuklEQVR4nO2bwY3DMAwEZcOPKyd9pf93roTlY2AMiN0CBlqtSMoKcv19vr8D6DnXTXAOQznnPOe6KFCtZRCzInKPai2Dai2DfNVP7dHd+INqLctnTVm0tZZBPmuyk73YmjJ+yNqli59a0XMYjtHa4tQa/3ugWsvCzpHQmi61Fm1WrWW1aN8EtWijai2rRTsCIRznHmGgtdZu3cN4U5uA1vZs3R7VWlatjUCykb34NlJrWZ0iI1DjzyCEA1q791rDUoMu/kZrXPVDLwjkyYZAi3s2Vf1Ca00tg6AFGRtbe3aU0Nrm1BBMe/ZEQmtNLQq8+lGgxY1t8fUYtMaAhJ/r1JKE/WjxkwZ2shePI1+rpd5GhNZ0U0S4R7rGpoyfAZF3yE6RDFq8R3utUSDfzX/zIwsGso3snuwsMn6bNV1qyt9FIBB1rRFa8/0E3dTeBOn2iPs60llrahnkswamBoEW37OFf83b+6TR1AYgW/Ub/77Ynp3U1LJ8qbWxZXUcZTW1AaiNbQBiOB1HAzW1AaiNbQDSWTtNLYOE1qDUwOpnpOzZtnHU1AYgXWrCNuJbUcdRBPWbNmpxaosb2z8DGwjO1q+hpAAAAABJRU5ErkJggg==\" id=\"imageb7d9876621\" transform=\"scale(1 -1) translate(0 -265.68)\" x=\"357.12\" y=\"-33.84\" width=\"12.96\" height=\"265.68\"/>\n",
       "   <g id=\"LineCollection_1\"/>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 357.056688 300.339749 \n",
       "L 363.709488 300.339749 \n",
       "L 370.362288 300.339749 \n",
       "L 370.362288 34.227749 \n",
       "L 363.709488 34.227749 \n",
       "L 357.056688 34.227749 \n",
       "L 357.056688 300.339749 \n",
       "z\n",
       "\" style=\"fill: none; stroke: #cccccc; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pcb0c6a0f94\">\n",
       "   <rect x=\"53.504688\" y=\"34.227749\" width=\"285.696\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(translator, 'jag köpte lite grejer .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤔 Task 7: Use these heatmaps to inspect the attention patterns for selected Swedish sentences\n",
    "\n",
    "Try to find sentences for which the model produces reasonably good English translations. If you don't speak Swedish, use sentences from the validation data. It might be interesting to look at examples where the Swedish and the English word order differ substantially.\n",
    "\n",
    "Based on your exploration, **answer the following questions:**\n",
    "\n",
    "- What sentences did you try out? What patterns did you spot? Include example heatmaps in your notebook.\n",
    "    - I tried out the phrase 'jag köpte lite grejer.' The translation was 75% accurate as it translated the three Swedish words correctly except the last word as shown in my heatmap analysis.\n",
    "\n",
    "- Based on what you know about attention, did you expect your results? Was there anything surprising in them?\n",
    "  - Based on attention, I expected higher results. Surprisingly the results turned out differently than expected highlighting areas where we can enhance and delve deeper into the translation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**🥳 Congratulations on finishing this lab! 🥳**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-L5-WithSolutions.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "12f500e95db8c7000aae6810a3b3f88d1298056c5758c6b1fc4b18ff2c238050"
  },
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
